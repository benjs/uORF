{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import models.mip_nerf as mipnerf\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.1+cu113'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importlib.reload(mipnerf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from data import MultiscenesDataModule\n",
    "from util.options import parse_custom_options\n",
    "import shlex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = \"\"\"\n",
    "--train_dataroot '/home/benjs/data_uORF/1200shape_50bg'  --test_dataroot \"\" \\\n",
    "    --n_scenes 1 --n_img_each_scene 4 --display_grad \\\n",
    "    --load_size 128 --n_samp 64 --input_size 128 --supervision_size 64 --coarse_epoch 120 \\\n",
    "    --no_locality_epoch 60 --z_dim 64 --num_slots 5 --bottom \\\n",
    "    --batch_size 1 --num_threads 10 \\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 2021\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "opt = parse_custom_options(shlex.split(args))\n",
    "pl.seed_everything(opt.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching train dataset ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = MultiscenesDataModule(opt)  # create a dataset given opt.dataset_mode and other options\n",
    "dataset.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(mipnerf)\n",
    "model = mipnerf.uorfMipNerf()\n",
    "proj = mipnerf.MipProjection(frustum_size=[10, 10, 64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fixed locality\n",
      "torch.Size([4, 1, 100, 33])\n",
      "torch.Size([4, 1, 100, 64])\n",
      "torch.Size([4, 4, 100, 33])\n",
      "torch.Size([4, 4, 100, 64])\n"
     ]
    }
   ],
   "source": [
    "model.to('cuda')\n",
    "\n",
    "for batch_idx, batch in enumerate(dataset.train_dataloader()):\n",
    "    imgs, cam2world, cam2world_azi = batch\n",
    "\n",
    "    imgs = imgs.to('cuda')\n",
    "    cam2world = cam2world.to('cuda')\n",
    "    cam2world_azi = cam2world_azi.to('cuda')\n",
    "    \n",
    "    B, S, C, H, W = imgs.shape\n",
    "\n",
    "    if opt.fixed_locality:\n",
    "        nss2cam0 = cam2world[:, 0:1].inverse()\n",
    "    else:\n",
    "        print(\"fixed locality\")\n",
    "        nss2cam0 = cam2world_azi[:, 0:1].inverse()\n",
    "    \n",
    "    N = B*S\n",
    "    cam2world = cam2world.view(N, 4, 4)\n",
    "    rays = proj.get_rays(cam2world)\n",
    "\n",
    "    z_vals = torch.ones((1, 5, 64), device=cam2world.device)\n",
    "\n",
    "    out = model(z_vals, rays)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.],\n",
       "        [3.],\n",
       "        [3.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 4) * torch.arange(4)\n",
    "a[..., 3:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 64, 30])\n",
      "torch.Size([4, 10, 10, 33])\n",
      "torch.Size([400, 64, 3])\n",
      "torch.Size([400, 64, 3])\n",
      "torch.Size([400, 65])\n"
     ]
    }
   ],
   "source": [
    "t_vals, samples = mipnerf.sample_along_rays(\n",
    "        rays.origins.flatten(end_dim=-2),\n",
    "        rays.directions.flatten(end_dim=-2),\n",
    "        rays.radii.flatten(end_dim=-2),\n",
    "        64,\n",
    "        rays.near.flatten(end_dim=-2),\n",
    "        rays.far.flatten(end_dim=-2)\n",
    "    )\n",
    "\n",
    "samples_enc = mipnerf.integrated_pos_enc(\n",
    "    samples,\n",
    "    0,\n",
    "    5\n",
    ")\n",
    "\n",
    "viewdirs_enc = mipnerf.pos_enc(\n",
    "    rays.viewdirs,\n",
    "    0,\n",
    "    5\n",
    ")  # [n_scenes*n_rays, 2*3*max_exp + 3]\n",
    "\n",
    "print(samples_enc.shape)\n",
    "print(viewdirs_enc.shape)\n",
    "print(samples[0].shape)\n",
    "print(samples[1].shape)\n",
    "print(t_vals.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0041, 0.0010, 0.0009], device='cuda:0')\n",
      "tensor([0.0044, 0.0021, 0.0021], device='cuda:0')\n",
      "tensor([0.0049, 0.0040, 0.0040], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(samples[1][0, 0])\n",
    "print(samples[1][0, 32])\n",
    "print(samples[1][0, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0022, 0.0004, 0.0033], device='cuda:0')\n",
      "tensor([0.0030, 0.0017, 0.0038], device='cuda:0')\n",
      "tensor([0.0043, 0.0038, 0.0046], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(samples[1][8000, 0])\n",
    "print(samples[1][8000, 32])\n",
    "print(samples[1][8000, 63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MipNerf(\n",
      "  (mlp): MipMLP(\n",
      "    (before_skip): Sequential(\n",
      "      (0): Linear(in_features=94, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (after_skip): Sequential(\n",
      "      (0): Linear(in_features=158, out_features=64, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (3): ReLU(inplace=True)\n",
      "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "    (to_density): Linear(in_features=64, out_features=1, bias=True)\n",
      "    (condition_bottleneck): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (condition_align): Sequential(\n",
      "      (0): Linear(in_features=97, out_features=32, bias=True)\n",
      "      (1): ReLU(inplace=True)\n",
      "    )\n",
      "    (to_rgb): Linear(in_features=32, out_features=3, bias=True)\n",
      "  )\n",
      "  (rgb_activation): Sigmoid()\n",
      "  (density_activation): Softplus(beta=1, threshold=20)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aaf78a186a1d6e0c4a65e466fece666bf3ffd142317b2e995ceac2a0e43c9c0a"
  },
  "kernelspec": {
   "display_name": "Python (uorf-env)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
